#!/usr/bin/python

# Bugs: 
# * @cite:some at end of line, or @cite:some, something.
# * don't work with iso encoding only utf8
 
# TODOs:
# * refactor most behaviour to a base class (done in-flight and lost)
# * use @toc in the .wiki file
# * deactivate implicit <pre> mode when in explicit "{{{ }}}" <pre> mode
# * bullets should allow breaking line into a new line with spaces.

import glob
import os.path
import re
import sys

enableLaTeX = True
enableHtml = True
forceRebuild = True

def htmlBibliographyText(match) :
	id = match.group(1)
	context = dict(id=id)
	try: context.update(bibEntries[id])
	except KeyError:
		print "Bibliography id not found:", id
		return r"<a class='bibref' href='bibliography.bib.html#%(id)s'>[%(id)s]</a>"%context
	except TypeError:
		print "No bibliography files found:", id
		return r"<a class='bibref' href='bibliography.bib.html#%(id)s'>[Error %(id)s]<span class='tooltip'>No bibliography file found.</span></a>"%context
	result = [
		"<a class='bibref' href='bibliography.bib.html#%(id)s' target='bibliography'>[%(id)s]",
		"<span class='tooltip'>",
	]
	result += [ "<span class='bibref%s'>%%(%s)s.</span> "%(field,field)
		for field in [
			"author", 
			"title",
			"school",
			"booktitle",
			"journal",
			"number",
			"pages",
			"editor",
			"location",
			"address",
			"month",
			"year",
			"url",
		] if field in context.keys() ]
	result.append("</span></a>")
	return "".join(result)%context

inlineHtmlSubstitutions = [  # the order is important
	(r"'''(([^']|'[^']|''[^'])*)'''", r"<b>\1</b>"),
	(r"''(([^']|'[^'])*)''", r"<em>\1</em>"),
	(r"\[\[(\S+)\s([^\]]+)\]\]", r"<a href='\1'>\2</a>"),
	(r"\[\[(\S+)\]\]", r"<a href='\1'>\1</a>"),
	(r"\[(http://\S+)\s([^\]]+)\]", r"<a href='\1'>\2</a>"),
	(r"\[(http://\S+)\]", r"<a href='\1'>\1</a>"),
	(r"@cite:([-+_a-zA-Z0-9]*)", htmlBibliographyText),
	(r"`([^`]+)`", r"<img src='http://www.forkosh.dreamhost.com/mimetex.cgi?\1' />"),
	(r"{{{", r"<pre>"),
	(r"}}}", r"</pre>"),
	(r"^@toc\s*$", r"%(toc)s"),
]
inlineLatexSubstitutions = [  # the order is important
	(r"'''(([^']|'[^']|''[^'])*)'''", r"{\\bf \1}"),
	(r"''(([^']|'[^'])*)''", r"{\\em \1}"),
	(r"\[\[(\S+)\s(.+)\]\]", r"\2\\footnote{\\url{\1}}"),
	(r"\[\[(\S+)\]\]", r"\\url{\1}"),
	(r"@cite:([-+_a-zA-Z0-9]*)", r"\cite{\1}"),
	(r"`([^`]+)`", r"$\1$"),
]

header = re.compile(r"^(=+)([*]?)\s*([^=]+?)\s*\1\s*$")
headersHtml = [
	r"<h1 id='toc_%(n)s'>%(title)s</h1>",
	r"<h2 id='toc_%(n)s'>%(title)s</h2>",
	r"<h3 id='toc_%(n)s'>%(title)s</h3>",
	r"<h4 id='toc_%(n)s'>%(title)s</h4>",
]
headersLatex = [
	r"\chapter{%(title)s}",
	r"\section{%(title)s}",
	r"\subsection{%(title)s}",
	r"\subsubsection{%(title)s}",
]

li  = re.compile(r"^([*#]+)(.*)")
pre = re.compile(r"^[ \t](.*)")
var = re.compile(r"^@([^:]*): (.*)")
fig = re.compile(r"^Figure:[\s]*([^\s]+)[\s]*([^\s]+)(.*)");
todo = re.compile(r"^TODO:[\s]*(.+)");
label = re.compile(r"^Label:[\s]*([^\s]+)");
div = re.compile(r"^([a-zA-Z0-9]+):$")

divMarkersLatex = {
	'Abstract' : ('\\begin{abstract}', '\\end{abstract}'),
	'Keywords' : ('\\begin{keywords}', '\\end{keywords}'),
	'Equation' : ('\\begin{equation}', '\\end{equation}'),
	'Math' : ('\\[', '\\]'),
#TODO: add new keys in html here
}

divMarkersHtml = {
	'Abstract' : ('<div class="abstract"><b>Abstract:</b>', '</div>'),
	'Keywords' : ('<div class="keywords"><b>Keywords:</b>', '</div>'),
	'Equation' : ("<div class='equation'><div><img src='http://www.forkosh.dreamhost.com/mimetex.cgi?\\Large{", "}' /></div></div>"),
	'Math'     : ("<div class='equation'><div><img src='http://www.forkosh.dreamhost.com/mimetex.cgi?\\Large{", "}' /></div>"),
	'TODO'     : ('<div class="todo"><b>TODO:</b>', '</div>'),
	'Comment'  : ('<div class="comment"><b>Comment:</b>', '</div>'),
	'Definition'  : ('<div class="definition"><b>Definition:</b>', '</div>'),
	'Lemma'  : ('<div class="lemma"><b>Lemma:</b>', '</div>'),
	'Proof'  : ('<div class="proof"><b>Proof:</b>', '</div>'),
	'Theorem'  : ('<div class="theorem"><b>Theorem:</b>', '</div>'),
	'Corollary'  : ('<div class="corollary"><b>Corollary:</b>', '</div>'),
}

defaultSkeleton = """
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
    "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" >

<!-- USING DEFAULT WIKO SKELETON. skeleton.html NOT FOUND -->

<head>
<title>%(title)s</title>
<meta name="author" content="%(author)s">
<alink rel='stylesheet' href='style.css' type='text/css'/>
<style type='text/css'>
.bibref
{
    position: relative; /*this is the key*/
    z-index:24;
}

a.bibref span.tooltip
{
    display: none;
}

a.bibref:hover
{
    z-index:25;
	text-decoration: none;
}

a.bibref:hover span.tooltip
{
	display: block;
	position: absolute;
	text-align: left;
	text-decoration: none;
	white-space: normal;
	padding: 1ex 1em;
	width: 20em;
	top: 1em;
	left: 1em;
	margin: auto;
	font-weight: normal;
	border: 1px solid #0cf;
	background-color:#cff;
	color:#000;
	opacity: 0.9;
}
a.bibref:hover span.tooltip *
{
	text-decoration: none;
}

a.bibref span.tooltip span.bibrefauthor
{
	display: block;
	font-weight: bold;
    color: green;
}

a.bibref span.tooltip span.bibreftitle
{
	display: block;
	color: #922;
	font-weight: bold;
    font-style: italic;
}

a.bibref:hover span.tooltip:before
{
	float: right;
	content: url(stock_book_open.png);
}
</style>
</head>
<body>
%(content)s
<div style='position:fixed; bottom:2px; right:2px; padding: 0pt 4pt; background-color:#999; color: grey'>Generated by <a href='http://wiko.sourceforge.net'>WiKo</a></div>
</body>
</html>
"""

def stripUtfMarker(content) :
	import codecs
	if content.startswith( codecs.BOM_UTF8 ):
		encoded = unicode(content,"utf8")
		stripped = encoded.lstrip( unicode( codecs.BOM_UTF8, "utf8" ) )
		return stripped.encode("utf8")
	return content
#		content = content[3:] # remove the utf8 marker

def readUtfSafe(filename) :
	return stripUtfMarker(file(filename).read())

class WikiCompiler :

	def compileInlines(self, inlines) :
		self.inlines = [ (re.compile(wikipattern), substitution) 
			for wikipattern, substitution in inlines  ]
	def substituteInlines(self, line) :
		for compiledPattern, substitution in self.inlines :
			line = compiledPattern.sub(substitution, line)
		return line


	def closeAnyOpen(self) :
		if self.closing == "" : return
		self.result.append(self.closing)
		self.closing=""
	def openBlock(self,opening,closing):
		self.closeAnyOpen()
		self.result.append(opening)
		self.closing=closing

	def addToc(self, level, title) :
		self.toc.append( (level, title) )
		return len(self.toc)
	def buildToc(self) :
		"""Default, empty toc"""
		return ""

	def process(self, content) :
		self.itemLevel = ""
		self.closing=""
		self.result=[]
		self.spanStack = []
		self.toc = []
		self.vars = {
			'title': '',
			'author': '',
		}
		for line in content.splitlines() :
			self.processLine(line)
		self.processLine("")
		self.vars["content"] = ("\n".join(self.result)) % {
			'toc': self.buildToc(),
		}
		return self.vars


class LaTeXCompiler(WikiCompiler) :
	def __init__(self) :
		self.compileInlines(inlineLatexSubstitutions)
		self.headerPatterns = headersLatex
	def processLine(self, line) :
		newItemLevel = ""
		liMatch = li.match(line)
		preMatch = pre.match(line)
		headerMatch = header.match(line)
		varMatch = var.match(line)
		figMatch = fig.match(line)
		todoMatch = todo.match(line)
		labelMatch = label.match(line)
		divMatch = div.match(line)
		if liMatch :
			self.closeAnyOpen()
			newItemLevel = liMatch.group(1)
			line = "%s\item %s" %("\t"*len(newItemLevel), liMatch.group(2) )
		while len(newItemLevel) < len(self.itemLevel) or  \
				self.itemLevel != newItemLevel[0:len(self.itemLevel)]:
#			print "pop '", self.itemLevel, "','", newItemLevel, "'"
			tag = "itemize" if self.itemLevel[-1] is "*" else "enumerate"
			self.result.append("%s\\end{%s}"%("\t"*(len(self.itemLevel)-1),tag))
			self.itemLevel=self.itemLevel[0:-1]
		if line=="" :
			self.closeAnyOpen()
		elif preMatch:
			if self.closing != "\\end{quote}" :
				self.openBlock("\\begin{quote}", "\\end{quote}")
			line=line[1:] # remove the pre indicator space
		elif varMatch :
			self.vars[varMatch.group(1)] = varMatch.group(2)
			return
		elif figMatch :
			self.closeAnyOpen()
			flags = [ flag.strip() for flag in figMatch.group(3).split() if flag.strip() ]
			imageFlags = []
			if "rotated90" in flags :
				imageFlags.append("angle=90")
			if "halfSize" in flags:
				imageFlags.append("scale=.5")
			else:
				imageFlags.append("width=4.8in")
			sizeSpecifier = "[" + ",".join(imageFlags) + "]"
			print "flags:", sizeSpecifier
			self.openBlock(
				"\\begin{figure*}[htbp]\n"
				"\\begin{center}\\includegraphics%(size)s{%(img)s}\end{center}\n"
				"\\caption{%%%%"%{
					'img': figMatch.group(2),
					'size': sizeSpecifier,
					},
				"}\n\\label{%(id)s}\n"
				"\\end{figure*}\n"%{
					'id':figMatch.group(1)},
				)

			return
		elif todoMatch :
			line="\\marginpar{\\footnotesize TODO: %s}"%todoMatch.group(1)
		elif labelMatch :
			line="\label{%s}"%labelMatch.group(1)
		elif headerMatch :
			self.closeAnyOpen()
			title = headerMatch.group(3)
			level = len(headerMatch.group(1))
			n=self.addToc(level,title)
			line = self.headerPatterns[level-1]%{
				"title": title,
				"label": n,
				"level": level,
			}
		elif not liMatch : 
			if divMatch :
				divType = divMatch.group(1)
				try :
					opening, closing = divMarkersLatex[divType]
					self.openBlock(opening, closing)
					return
				except: 
					print "Not supported block class '%s'" % divType
		# Equilibrate the item level
		while len(self.itemLevel) != len(newItemLevel) :
			self.closeAnyOpen()
#			print "push '", self.itemLevel, "','", newItemLevel, "'"
			levelToAdd = newItemLevel[len(self.itemLevel)]
			tag = "itemize" if levelToAdd is "*" else "enumerate"
			self.result.append("%s\\begin{%s}"%("\t"*len(self.itemLevel),tag))
			self.itemLevel += levelToAdd
		line = self.substituteInlines(line)	
		self.result.append(line)


class HtmlCompiler(WikiCompiler) :
	def __init__(self, bibEntries={}) :
		self.compileInlines(inlineHtmlSubstitutions)
		self.headerPatterns = headersHtml
		self.bibEntries = bibEntries
	def buildToc(self) :
		result = []
		lastLevel = 0
		i=1
		result+=["<h2>Index</h2>"]
		result+=["<div class='toc'>"]
		for (level, item) in self.toc :
			while lastLevel < level :
				result += ["<ul>"]
				lastLevel+=1
			while lastLevel > level :
				result += ["</ul>"]
				lastLevel-=1
			result+=["<li><a href='#toc_%i'>%s</a></li>"%(i,item)]
			i+=1
		while lastLevel > 0 :
			result += ["</ul>"]
			lastLevel-=1
		result += ["</div>"]
		return "\n".join(result)

	def processLine(self, line) :
		newItemLevel = ""
		liMatch = li.match(line)
		preMatch = pre.match(line)
		headerMatch = header.match(line)
		varMatch = var.match(line)
		figMatch = fig.match(line)
		todoMatch = todo.match(line)
		labelMatch = label.match(line)
		divMatch = div.match(line)
		if liMatch :
			self.closeAnyOpen()
			newItemLevel = liMatch.group(1)
			line = "%s<li>%s</li>" %("\t"*len(newItemLevel), liMatch.group(2) )
		while len(newItemLevel) < len(self.itemLevel) or  \
				self.itemLevel != newItemLevel[0:len(self.itemLevel)]:
#			print "pop '", self.itemLevel, "','", newItemLevel, "'"
			tag = "ul" if self.itemLevel[-1] is "*" else "ol"
			self.result.append("%s</%s>"%("\t"*(len(self.itemLevel)-1),tag))
			self.itemLevel=self.itemLevel[0:-1]
		if line=="" :
			self.closeAnyOpen()
		elif preMatch:
			if self.closing != "</pre>" :
				self.openBlock("<pre>","</pre>")
			line=line[1:] # remove the pre indicator space
		elif varMatch :
			self.vars[varMatch.group(1)] = varMatch.group(2)
			print "Var '%s': %s"%(varMatch.group(1),varMatch.group(2))
			return
		elif figMatch :
			self.closeAnyOpen()
			self.openBlock(
				"<div class='figure' id='%(id)s'><img src='%(img)s' alt='%(id)s'/><br />"%{
						'id':figMatch.group(1),
						'img': figMatch.group(2),
						},
				"</div>")
			return
		elif todoMatch :
			line=" <span class='todo'>TODO: %s</span> "%todoMatch.group(1)
		elif labelMatch :
			line=" <a name='#%s'></a>"%labelMatch.group(1)
		elif headerMatch :
			self.closeAnyOpen()
			title = headerMatch.group(3)
			level = len(headerMatch.group(1))
			n=self.addToc(level,title)
			line = self.headerPatterns[level-1]%{
				"title": title,
				"n": n,
				"level": level,
			}
		elif not liMatch : 
			if divMatch :
				divType = divMatch.group(1)
				try :
					opening, closing = divMarkersHtml[divType]
					self.openBlock(opening, closing)
					return
				except: 
					print "Not supported block class '%s'" % divType
			elif self.closing == "" :
				self.openBlock("<p>","</p>")
		# Equilibrate the item level
		while len(self.itemLevel) != len(newItemLevel) :
			self.closeAnyOpen()
#			print "push '", self.itemLevel, "','", newItemLevel, "'"
			levelToAdd = newItemLevel[len(self.itemLevel)]
			tag = "ul" if levelToAdd is "*" else "ol"
			self.result.append("%s<%s>"%("\t"*len(self.itemLevel),tag))
			self.itemLevel += levelToAdd
		line = self.substituteInlines(line)	
		self.result.append(line)

skeletonFileName = "skeleton.html"
try: skeleton = readUtfSafe(skeletonFileName)
except: skeleton = defaultSkeleton

def needsRebuild(target, source) :
	if forceRebuild: return True
	if not os.path.exists(target) : return True
	if os.path.getmtime(target)<os.path.getmtime(source): return True
	if not os.access(skeletonFileName, os.F_OK) : return False
	if os.path.getmtime(target)<os.path.getmtime(skeletonFileName) : return True
	return False

def generateHtmlBibliography(outputFilename, bibfiles) :
	if not bibfiles : return
	print "Generating HTML bibliography..."

	return generateHtmlBibliographyRaw(outputFilename, bibfiles)
	#PAU i get errors (missing comma)
	try: import _bibtex as bibtex
	except: return generateHtmlBibliographyRaw(outputFilename, bibfiles)
	return generateHtmlBibliographyPretty(outputFilename, bibfiles)

def generateHtmlBibliographyRaw(outputFilename, bibfiles) :
	result = []
	bibfilename = "bibliography.bib.html"
	entry = re.compile(r"@\w*{([^,]*),")
	for bibfile in bibfiles :
		for line in file(bibfile) :
			m = entry.search(line)
			if m and not 'comment' in line:
				id = m.group(1).strip()
				result += ["<a id='%s' />\n"%id]
			result.append(line)
	# TODO: Is it needed to have a 
	file(bibfilename, "w").write(skeleton%dict(
		content="<pre>"+"".join(result)+"</pre>",
		title="Bibliography",
		author="",
		revision="",
		prev="",
		next="",
		wikiSource='',
		))
	return {} # no hoverable bibliography

def generateHtmlBibliographyPretty(outputFilename, bibfiles) :
	import _bibtex as bibtex
	def bibIterator( file ) :
		while True :
			entry = bibtex.next(file)
			if entry: yield entry
			else: return
	entries = {}
	output = []
	for filename in bibfiles :
		bibfile = bibtex.open_file(filename,1)
		for id, kind, byteOffset, lineOffset, keys in bibIterator(bibfile) :
			output += ["<p><a name='%s'></a><b>%s</b> <b>%s</b></p><ul>"%(id,kind,id)]
			entryDict = {}
			for key, value in keys.iteritems() :
				expanded = bibtex.expand(bibfile, value, -1)
				if len(expanded) is 3 :
					expanded = tuple(list(expanded)+[None])
				elif len(expanded) is 6 : # year
					expanded = expanded[0:-2]
				elif len(expanded) is not 4 : print "Warning: unknown bibliography tuple:", id, key, expanded; continue
				foo, bar, text, content = expanded
				if not text : continue
				output += ["<li><b>%s:</b> %s</li>" % (key, text)]
				entryDict[key]=text
			entryDict["kind"] = kind
			entries[id] = entryDict
			output += [ "</ul>" ]
	file(outputFilename, "w").write(skeleton%dict(
		content="\n".join(output),
		title="Bibliography",
		author="",
		revision="",
		prev="",
		next="",
		wikiSource='',
		))
	return entries

# Generate bibliography
bibEntries = generateHtmlBibliography("bibliography.bib.html", glob.glob("*.bib"))

# Generate HTML with HTML content files + skeleton
for contentFile in glob.glob("content/*.html") :
	target = os.path.basename(contentFile)
	if not needsRebuild(target, contentFile) :
		print target, "is up to date."
		continue
	print "Generating", target, "from", contentFile, "..."
	content = readUtfSafe(contentFile)
	file(target,"w").write(skeleton%{'title':'', 'author':'','content':content})

# Generate LaTeX and HTML from wiki files

def fileNamesBasesForExtension(extension) :
	return set([ os.path.splitext(file)[0] for file in glob.glob("*."+extension) ])

# TeX skeletons are not generated from wiki files
texSkeletons = fileNamesBasesForExtension("tex") - fileNamesBasesForExtension("wiki")
# ...and contain \documentclass directive
texSkeletons = [ texSkeleton 
		for texSkeleton in texSkeletons
		if file(texSkeleton+".tex").read().find(r"\documentclass") != -1
	]

for contentFile in glob.glob("*.wiki") :
	base = os.path.basename(contentFile)
	target = "".join(os.path.splitext(base)[0:-1])+".html"
	targetTex = "".join(os.path.splitext(base)[0:-1])+".tex"
	if not needsRebuild(target, contentFile) :
		print target, "is up to date."
		continue
	content = readUtfSafe(contentFile)
	if enableHtml :
		print "Generating", target, "from", contentFile, "..."
		htmlResult = HtmlCompiler(bibEntries).process(content)
		htmlResult['wikiSource']=contentFile;
		file(target,"w").write(skeleton%htmlResult)
	if enableLaTeX and len(texSkeletons):
		print "Generating", targetTex, "from", contentFile, "..."
		texResult = LaTeXCompiler().process(content)
		file(targetTex,"w").write(texResult['content'])


print "Generating blog..."

def readBlogEntries(blog) :
	blogEntries = []
	tags=set()
	for contentFile in glob.glob("blog/*.wiki") :
		entry = HtmlCompiler(bibEntries).process(readUtfSafe(contentFile))
		entry['name'] = os.path.splitext(os.path.split(contentFile)[-1])[0]
		entry.setdefault('tags',"")
		entry['splittedTags']=[tag.strip() for tag in entry["tags"].split(",") if tag!=""]
		tags=tags.union(entry['splittedTags'])
		entry['linkedTags']=', '.join([
			"<a href='blog.tag.%(tag)s.html'>%(tag)s</a>"%{'tag':tag} 
				for tag in entry['splittedTags']])
		entry["rsscategories"]="\n".join([
			"<category domain='http://www.blogger.com/atom/ns#'>%s</category>"%tag 
				for tag in entry["splittedTags"] ])
		publishedTime = datetime.strptime(entry['timestamp'],  "%d/%m/%Y %H:%M")
		updatedTime = datetime.utcfromtimestamp(os.path.getmtime(contentFile))
		entry['timestamp'] = str(publishedTime)
		entry["updatedtime"] = updatedTime.isoformat() #  2007-07-21T11:47:11.001-07:00
		entry["publishedtime"] = publishedTime.strftime("%a, %d %b %Y %T") # was: Fri, 20 Jul 2007 18:10:00 +0000
		entry["entryid"] = "tag:blogger.com,1999:blog-36421488.post-8207308771074649324" # TODO
		entry['link'] = "blog.%s.html"%entry["name"]
		from xml.sax.saxutils import escape
		entry["encodedContent"] = escape(entry["content"])
		# fulluri was: http://vokicodder.blogspot.com/2007/07/simplifying-spectral-processing-in-clam.html
		entry["fulluri"] = blog["baseurl"] + "/" + entry["link"]
		blogEntries.append(entry)
	blogEntries.sort(key=lambda a: a['timestamp'], reverse=True)
	return blogEntries, tags

def generateBlog(blog, blogEntries, tags) :
	if not blogEntries: return
	tagPages = dict([(tag,[]) for tag in tags])
	blogEntryScheleton = readUtfSafe("blog/entryScheleton.html")
	blogScheleton = readUtfSafe("blog/skeleton.html")
	blogRssEntryScheleton = readUtfSafe("blog/rssEntryScheleton.rss")
	blogRssScheleton = readUtfSafe("blog/rssScheleton.rss")
	htmlentries = []
	rssItems = []
	for entry in blogEntries :
		print entry['timestamp'], entry['name'] , "|" , entry['title'] , "[" + entry["tags"]+']'
	for entry in blogEntries :
		targetBlog = entry['link']
		composed = blogEntryScheleton%entry
		htmlentries.append(composed)
		for tag in entry['splittedTags'] :
			tagPages[tag].append(composed)
		rssItems.append(blogRssEntryScheleton%entry)

	taglist=[(tag,len(entries)) for tag, entries in tagPages.iteritems()]
	taglist.sort(key=lambda a : a[1],reverse=True)
	blog['taglist'] = "\n".join([
		"<li><a href='blog.tag.%s.html'>%s&nbsp;(%i)</a></li>"%(
			tag,tag,nitems) for tag,nitems in taglist])
	for entry in blogEntries :
		blog['htmlentries'] = blogEntryScheleton % entry
		file(entry['link'],"w").write(blogScheleton % blog)
		

	blog.update({
		'htmlentries': "\n".join(htmlentries),
		'rssitems': "\n".join(rssItems),
	})
	file("blog.index.html","w").write(blogScheleton%blog)
	file("blog.rss","w").write(blogRssScheleton%blog)
	tagNotice = """<div class='blog_tagnotice'>Showing only entries labeled as <b>%s</b>.
<a href='blog.index.html'>Show all entries</a></div>"""
	for tag, tagEntries in tagPages.iteritems() :
		blog['htmlentries'] = "\n".join([tagNotice%tag]+tagEntries)
		file("blog.tag.%s.html"%tag,"w").write(blogScheleton%blog)

from datetime import datetime
# TODO: Should be a config file with default values
blog = {
	'title': "Voki Codder",
	'editor': "Vokimon",
	'description': "Code for the masses",
	'generator': "WiKo",
	'lastbuilddate': datetime.utcnow().ctime(), #strftime("%c"), # TODO: was 'Thu, 18 Oct 2007 17:13:32 +0000',
	'homeurl': "http://vokicodder.blogspot.com/",
	'baseurl': "localhost",
	'blogid' : "tag:blogger.com,1999:blog-36421488",
}

blogEntries, tags = readBlogEntries(blog)
generateBlog(blog, blogEntries, tags)


print "Generating download zones..."

def humanReadableSize(filename) :
	if os.path.isdir(filename) : return ""
	sufixes = [
		("P",1<<50),
		("T",1<<40),
		("G",1<<30),
		("M",1<<20),
		("K",1<<10),
	]
	size = os.path.getsize(filename)
	for suffix, scale in sufixes:
		if size/scale > 1.1:
			return "%.2f %sb"%(float(size)/scale, suffix)
	return str(size)+" b"

def humanReadableTime(filename) :
	if os.path.isdir(filename) : return ""
	return str(datetime.fromtimestamp(os.path.getmtime(filename)))

def generateDownloadZones(dirs, skeletonFilename, blacklist) :
	lineTemplate = "<tr><td style='width:100%%'><a href='%(filename)s'>%(filename)s</a></td><td>%(size)s</td><td>%(date)s</td></tr>"
	skeleton = readUtfSafe(skeletonFilename)
	for title, dirname in dirs:
		dirname = os.path.expanduser(dirname)
		if not os.access(dirname, os.X_OK):
			print "Not available: %s"%dirname
			continue
		print "Generating download index at '%s'"%dirname
		files = os.listdir(dirname)
		files = filter((lambda a : a not in blacklist ), files) # Filter blacklisted
		dirs = [dir+"/" for dir in filter((lambda a : os.path.isdir(os.path.join(dirname, a)) ), files) ]
		files = filter((lambda a : not os.path.isdir(os.path.join(dirname, a)) ), files) # Filter dirs
		files.sort()

		table = "\n".join( [ lineTemplate%{
				'filename': filename,
				'size': humanReadableSize(os.path.join(dirname, filename)),
				'date': humanReadableTime(os.path.join(dirname, filename)),
			} for filename in dirs + files ])
		content = "<h1> Downloads </h1>"
		content += "<h2> %s </h2>"%title
		content += "\n".join(["<table style='white-space:nowrap' width='100%'>",table,"</table>"])
		index = skeleton%{
			'title': title,
			'content': content,
			'author':'generated',
			'wikiSource':''
		}
		open(os.path.join(dirname,"index.html"),"w").write(index)

dzConfig = {
	'dirs' : [],
	'blacklist' : [
		"index.html",
		"style.css",
		"img",
	],
	'template' : skeletonFileName
}
try :
	dzConfig.update(eval(file("downloadZones.wiko").read()))
except :
	pass
if len(dzConfig['dirs']) :
	generateDownloadZones(dzConfig['dirs'], dzConfig['template'], dzConfig['blacklist'])

#os.system("(cd img; bash ./generate_figures.py)")

if enableLaTeX:
	for texSkeleton in texSkeletons :
		os.system("bibtex %s" % texSkeleton)
		os.system("pdflatex %s" % texSkeleton)


