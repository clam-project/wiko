#!/usr/bin/python

# Bugs: 
# * @cite:some at end of line, or @cite:some, something.
# * don't work with iso encoding only utf8
 
# TODOs:
# * refactor most behaviour to a base class (done in-flight and lost)
# * use @toc in the .wiki file
# * deactivate implicit <pre> mode when in explicit "{{{ }}}" <pre> mode
# * bullets should allow breaking line into a new line with spaces.

import glob
import os.path
import re
import sys
import subprocess
import urllib
import codecs

enableLaTeX = '--nolatex' not in sys.argv
enableHtml = '--nohtml' not in sys.argv
forceRebuild = '--force' in sys.argv
embeddedFormulas = '--embed-formulas' in sys.argv

# \marginpar{...} is problematic with two columns. for example in acmmm style:
# use this to use footnotes instead:
enableLaTeXMarginNotes = '--no-margin-notes' not in sys.argv
print "margins?", enableLaTeXMarginNotes

mimetexAvailable = os.system("mimetex 2>&1 > /dev/null") == 0
if mimetexAvailable: print "Using mimetex locally to generate formulas"
useRemoteFormulas = not mimetexAvailable or '--remote-formulas' in sys.argv
print "useRemoteFormulas:", useRemoteFormulas

def formulaIdGen(): a=0; yield a; a+=1
def equationIdGen(): a=0; yield a; a+=1

def formulaUri(latexContent) :
	if useRemoteFormulas :
		return "http://www.forkosh.dreamhost.com/mimetex.cgi?"+latexContent
	mimetex = subprocess.Popen(["mimetex","-d",latexContent], stdout=subprocess.PIPE)
	imageContent=mimetex.stdout.read()
	if embeddedFormulas :
		import base64
		url = "data:image/png;base64,"+ base64.b64encode(imageContent)
		return url
	if not os.access("formulas",os.F_OK) :
		os.mkdir("formulas")
	id = formulaIdGen.next()
	gifname = "formulas/eq%06i.gif"%id
	print "generating",gifname
	gif = open(gifname,'wb')
	gif.write(imageContent)
	gif.close()
	return gifname

class HtmlVerbatimProcessor :
	def __init__(self) :
		self.content=[]
	def __call__(self, line) :
		if line is None:
			return "\n".join(self.content)
		self.content.append(line)
		return ""

class HtmlFormulaProcessor :
	def __init__(self, match) :
		self.content=[]
	def __call__(self, line) :
		if line is None:
			return '"'+formulaUri("\Large{"+"".join(self.content)+"}")+'"'
		self.content.append(line.strip())
		return ""

class HtmlCodeProcessor :
	def __init__(self, match) :
		self.content=[]
		self.language=match.group(1) or "javascript"
	def __call__(self, line) :
		if line is not None:
			self.content.append(line)
			return ""
		try :
			from pygments import highlight
			from pygments.lexers import get_lexer_by_name
			from pygments.formatters import HtmlFormatter
		except:
			print >> sys.stderr, "Warning: Pygments package not available. Generating code without syntax highlighting."
			return "\n".join(self.content)
		file("style_code.css",'w').write(HtmlFormatter().get_style_defs('.code'))

		lexer = get_lexer_by_name(self.language, stripall=True)
		formatter = HtmlFormatter(linenos=False, cssclass="code")
		return highlight("\n".join(self.content), lexer, formatter)

class LaTeXCodeProcessor :
	def __init__(self, match) :
		self.language=match.group(1) or "javascript"
		self.content=[]
	def __call__(self, line) :
		if line is not None:
			self.content.append(line)
			return
		return "\n".join(self.content)

def htmlInlineFormula(match) :
	formula = match.group(1)
	return '<img class="inlineFormula" src="%s" alt="%s" />'%(formulaUri(formula), formula)

def htmlBibliographyText(match) :
	print "writing bibliography"
	id = match.group(1)
	context = dict(id=id)
	# bib file not found
	if bibEntries is None :
		print "No bibliography files found:", id
		return r"<a class='bibref' href='bibliography.bib.html#%(id)s'>[Error %(id)s]<span class='tooltip'>No bibliography file found.</span></a>"%context
	# using raw bibtex formating (bibtex package not available)
	if len(bibEntries)==0 :
		return r"<a class='bibref' href='bibliography.bib.html#%(id)s'>[%(id)s]</a>"%context

	if not bibEntries.has_key(id) :
		print "Bibliography id not found:", id
		return r"<a class='bibref' href='bibliography.bib.html#%(id)s'>[Error %(id)s]<span class='tooltip'>BibTeX key not found.</span></a>"%context
	
	context.update(bibEntries[id])
	result = [
		"<a class='bibref' href='bibliography.bib.html#%(id)s' target='bibliography'>[%(id)s]",
		"<span class='tooltip'>",
	]
	result += [ "<span class='bibref%s'>%%(%s)s.</span> "%(field,field)
		for field in [
			"author", 
			"title",
			"school",
			"booktitle",
			"journal",
			"number",
			"pages",
			"editor",
			"location",
			"address",
			"month",
			"year",
			"url",
		] if unicode(field,'utf8') in context.keys() ]
	result.append("</span></a>")
	return "".join(result)%context

inlineHtmlSubstitutions = [  # the order is important
	(r"'''(([^']|'[^']|''[^'])*)'''", r"<b>\1</b>"),
	(r"''(([^']|'[^'])*)''", r"<em>\1</em>"),
	(r"\[\[(\S+)\s([^\]]+)\]\]", r"<a href='\1'>\2</a>"),
	(r"\[\[(\S+)\]\]", r"<a href='\1'>\1</a>"),
	(r"\[(http://\S+)\s([^\]]+)\]", r"<a href='\1'>\2</a>"),
	(r"\[(http://\S+)\]", r"<a href='\1'>\1</a>"),
	(r"@cite:([-+_a-zA-Z0-9]+)", htmlBibliographyText),
	(r"`([^`]+)`", htmlInlineFormula),
#	(r"{{{", r"<pre>"),
#	(r"}}}", r"</pre>"),
	(r"^@toc\s*$", r"%(toc)s"),
	(r"^BeginProof\n*$", r"<div class='proof'><b>Proof:</b>"),
	(r"^EndProof\n*$", r"</div>"),
	(r"^BeginDefinition\n*$", r"<div class='definition'><b>Definition:</b>"),
	(r"^EndDefinition\n*$", r"</div>"),
	(r"^BeginTheorem\n*$", r"<div class='theorem'><b>Theorem:</b>"),
	(r"^EndTheorem\n*$", r"</div>"),
]
inlineLatexSubstitutions = [  # the order is important
	(r"'''(([^']|'[^']|''[^'])*)'''", r"{\\bf \1}"),
	(r"''(([^']|'[^'])*)''", r"{\\em \1}"),
	(r"\[\[(\S+)\s([^\]]+)\]\]", r"\2\\footnote{\\url{\1}}"),
	(r"\[\[(\S+)\]\]", r"\\url{\1}"),
	(r"@cite:([-+_a-zA-Z0-9]*)", r"\protect\cite{\1}"),
	(r"`([^`]+)`", r"$\1$"),
#	(r"{{{", ur"\\begin{verbatim}"),
#	(r"}}}", ur"\end{verbatim}"),
	(r"^BeginProof\n*$", r"\\begin{pro}"),
	(r"^EndProof\n*$", r"\\end{pro}"),
	(r"^BeginDefinition\n*$", r"\\begin{defin}"),
	(r"^EndDefinition\n*$", r"\\end{defin}"),
	(r"^BeginTheorem\n*$", r"\\begin{thma}"),
	(r"^EndTheorem\n*$", r"\\end{thma}"),
]

header = re.compile(r"^(=+)([*]?)\s*([^=]+?)\s*\1\s*$")
headersHtml = [
	r"<h1 id='toc_%(n)s'>%(title)s</h1>",
	r"<h2 id='toc_%(n)s'>%(title)s</h2>",
	r"<h3 id='toc_%(n)s'>%(title)s</h3>",
	r"<h4 id='toc_%(n)s'>%(title)s</h4>",
	r"<h5 id='toc_%(n)s'>%(title)s</h5>",
]
headersLatex = [
	r"\chapter{%(title)s}",
	r"\section{%(title)s}",
	r"\subsection{%(title)s}",
	r"\subsubsection{%(title)s}",
]

li  = re.compile(r"^([*#]+)(.*)")
quote = re.compile(r"^[ \t](.*)")
var = re.compile(r"^@([^:]*): (.*)")
fig = re.compile(r"^Figure:[\s]*([^\s]+)[\s]*([^\s]+)(.*)");
todo = re.compile(r"^TODO:[\s]*(.+)");
anno = re.compile(r"^:([^\s]+):[\s]*(.*)");
code = re.compile(r"^Code:[\s]*([^\s]+)?");
label = re.compile(r"^Label:[\s]*([^\s]+)");
div = re.compile(r"^([a-zA-Z0-9]+):$")
pre = re.compile(r"^{{{[\s]*([^\s])*")

divMarkersLatex = {
	'Abstract' : ('\\begin{abstract}', '\\end{abstract}'),
	'Keywords' : ('\\begin{keywords}', '\\end{keywords}'),
	'Equation' : ('\\begin{equation}', '\\end{equation}'),
#	'Math' : ('\\[', '\\]'),
	'Theorem': ('\\begin{thma}', '\\end{thma}'),
	'Lemma': ('\\begin{lem}', '\\end{lem}'),
	'Corollary': ('\\begin{cor}', '\\end{cor}'),
	'Proof': ('\\begin{pro}', '\\end{pro}'),
	'Definition': ('\\begin{defin}', '\\end{defin}'),
	#TODO: add new keys added in html
}

divMarkersHtml = {
	'Abstract' : ('<div class="abstract"><b>Abstract:</b>', '</div>'),
	'Keywords' : ('<div class="keywords"><b>Keywords:</b>', '</div>'),
	'Equation' : ("<div class='equation'><img src=", " /><!--<span class='eqnumber'>(123)</span>--></div>", HtmlFormulaProcessor),
	'Math'     : ("<div class='equation'><img src=", " /></div>", HtmlFormulaProcessor),
	'TODO'     : ('<div class="todo"><b>TODO:</b>', '</div>'),
	'Comment'  : ('<div class="comment"><b>Comment:</b>', '</div>'),
	'Definition'  : ('<div class="definition"><b>Definition:</b>', '</div>'),
	'Lemma'    : ('<div class="lemma"><b>Lemma:</b>', '</div>'),
	'Proof'    : ('<div class="proof"><b>Proof:</b>', '</div>'),
	'Theorem'  : ('<div class="theorem"><b>Theorem:</b>', '</div>'),
	'Corollary': ('<div class="corollary"><b>Corollary:</b>', '</div>'),
}

defaultStyleSheet = u"""
.figure {
	border: solid 1pt grey;
	display: block;
	text-align: center;
}
.rightfigure {
	border: solid 1pt grey;
	float: right;
	margin-left: 3em;
}
.abstract {
	padding:2em;
}
.todo {
/*	display: none;*/
	color: red;
	background-color: yellow;
	padding: 3pt;
}

.bibref
{
	/* Needed for the tooltip */
    position: relative;
    z-index:0;
}
.anno
{
	/* Needed for the tooltip */
    position: relative;
    z-index:0;
	cursor: pointer;
}
.bibref:hover
{
	z-index:25;
}
.anno:hover
{
	z-index:25;
}

span.tooltip
{
    display: none;
}
:hover > span.tooltip
{
	display: block;
	position: absolute;
	text-align: left;
	text-decoration: none;
	white-space: normal;
	padding: 1ex 1em;
	width: 20em;
	top: 1em;
	left: 1em;
	margin: auto;
	font-weight: normal;
	opacity: 0.9;
}
.bibref span.bibrefauthor
{
	display: block;
	font-weight: bold;
    color: green;
}

.bibref span.bibreftitle
{
	display: block;
	color: #922;
	font-weight: bold;
    font-style: italic;
}

.bibref:hover > span.tooltip:before
{
	float: right;
	content: url('stock_book_open.png');
	content: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAYAAADgdz34AAAABmJLR0QA/wD/AP+gvaeTAAAEzUlEQVR42qWWXWgUVxTHfzOT3dnNZvOdDaaGaNG11aiFqG2tkRr6IdiaUCiBiggtFFuFUjQ+VCjSQh9KKS2t9KEfVrAtFRT0oamhjS2FWI2tJjHRGI1JzIe72U2yM9nNzu7O3D54N8QQobYHDhdmmPO7/3PuPWdgYdPq6+ufAUSOyy2Ap4BCwA2o/E/Ttm/f/qyvoFgcPnJc/NF2YQIQQBAoBlyA8l+Dq8AaX0GxeO+Tb0QsFhPdV6+JXH+hAHYBSwDff1WhAmuKyheLDz77VkxOTYn+/n7R3d0tvjxy7IpUsRYofRAV6py1Or+kvGP/wfd5Y2cDkfFxIpEIpmmyemVwVV5BCUA1kCdr8a8BKlBdWrGkY0/Tu9beXS8xOjLC5OQkHo+HdDqNK0dj95t7WoFjgB/wAjnyW2UBvwewqrwq2LFn3zvGgd079FAohOM4pFIpMpkMtm1j2za1T9Qs9ReVZVUUSCW5EpZ1j1SXkwWpQOeu1/eG3nr15fxwKIRlWdi2jeM42LaN1+vFMAzMRNK945XGcE1NzffADSAKmEBc+gBwANgg4S5AUbfU7+Txx1b6Muk0lmURiUTuCWzbNlYqnRgJRUsbXnwhcPHiRYQQC3nZ01vqXgPqgDKpTtMGejsPzbgDYw3PbSo0TZO0BKmqSjwex+Vy0Xc7HC3Kcxc0NNQriUQCw5wmnkgQjydIpTMAhMPjAhR/c/NPW4AfgBkgqQKbRwb7qo6eaDYDgQBut3s2/z6fj8HhO2OZGSOwYf06BUD3eMjPz591XddRUBgaGlR+be8GiM09BCrQ8/fZU/x27vKEoijYto2maUxPT2Oa04Y5Y3nKigvUYDCIZVlEo1EMw8AwDCzLQtNUQuNhzl/qEW2tP6vAp0AGsAGhAkmgLjQyWPXdqZbpyspKNE3D7XbTe2v4pltJFzY2NgKg6zolJSXouj7rjm3T1vYnw6Eok6FhgEuy+EnAVoEU0NX+ywla2y5FVfXu3RsYHLrqdSlrN23cqNzNcRjDMEhZ1mzwHE1laOg2UTPJV4c/VjLpVBNgyDQlAUeVUmaAuonwaNXXx0/HKioqrMikUVT50CI1GAwCEAgE0HWdpEyTqiikUhl6rt/gfEcvscgd5PGdlApSgJMDOFkV55p/pKh00cST1cvMpZWL1mzbtg3LsrAsC0cI/H4/LpcLkQeKqhCKRJicTnLy6OcATXLnMSAh6yBy5I2eVXG980LrydPKWL7Pw/Nbt+LPy0PXdQBisRiapuHxenFsh5v9g5z5vZ2EOZXd/ZTcfVo2RzQJEHKNTYRuHwg8usnd0dWtPbx8hUhaaSVmxsn1ulFVFZ/Ph6qqdPdc40rfAB8d2o/j2E3ALeCOhKTmA+ba6b6OtvKSsvIlLS0t7s6+YS509Ymx8IS4MTQqpoyE4vXq9PTepP1yl2g7e0YBvgBCQESmx84Gm99yXbJblkqvAlYAW5avXr+5el0tLrfuLKtaTEYI8eHBvRqwD/gLGALCMtXO/QCKhOTKhpXtkD45zR4BaqvX1dbFzRi3ejvfBq4Ao1KBkS3u/QDZZ5q86jkS6JGwXAnLlZ04CUzIzmpkj+b8YPez7PDIDiXXHJgu36VlzmcWCs4D/B3Mh2UnmSML6iwUHOAfyqIygtirwoUAAAAASUVORK5CYII=');
}

.bibref:hover span.tooltip
{
	border: 1px solid #9cf;
	background-color:#cff;
	color:#000;
}

.anno:hover span.tooltip
{
	border: 1px solid #cf0;
	background-color:#ff9;
	color:#000;
}

.anno:hover
{
	text-decoration: none;
}

.bibref:hover
{
	text-decoration: none;
}

div.equation
{
	padding: 1ex;
	margin: 4pt auto; 
	text-align: center;
	border: solid 1pt #EEE;
}
.equation .eqnumber
{
	float: right;
}

img.inlineFormula
{
	vertical-align: middle;
}

.menu li
{
	display: inline;
}
.menu li.cloud0 { font-size:60%%;}
.menu li.cloud1 { font-size:70%%;}
.menu li.cloud2 { font-size:80%%;}
.menu li.cloud3 { font-size:90%%;}
.menu li.cloud4 { font-size:100%%;}
.menu li.cloud5 { font-size:105%%;}
.menu li.cloud6 { font-size:110%%;}
.menu li.cloud7 { font-size:120%%;}
.menu li.cloud8 { font-size:130%%;}
.menu li.cloud9 { font-size:140%%;}
.menu li.cloud10 { font-size:150%%;}
.menu
{
	padding: inherit;
	text-align: justify;
}
"""

defaultSkeleton = u"""
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
    "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" >

<!-- USING DEFAULT WIKO SKELETON. skeleton.html NOT FOUND -->

<head>
<title>%(title)s</title>
<!--base-->
<meta name="author" content="%(author)s">
<alink rel='stylesheet' href='style.css' type='text/css'/>
<link rel='stylesheet' href='style_code.css' type='text/css'/>
<style type='text/css'>
"""+defaultStyleSheet +"""
</style>
</head>
<body>
%(content)s
<div style='position:fixed; bottom:2px; right:2px; padding: 0pt 4pt; background-color:#999; color: grey'>Generated by <a href='http://wiko.sourceforge.net'>WiKo</a></div>
</body>
</html>
"""

defaultBlogSkeleton = u"""\
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
    "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" >
<head>
<title>%(title)s</title>
<!--base-->
<style type='text/css'>
"""+defaultStyleSheet +"""
</style>
<link rel='stylesheet' href='style.css' type='text/css'/>
<link rel='stylesheet' href='style_code.css' type='text/css'/>
<!-- TODO: Style sheets -->
</head>
<body>
<div id='sidebar'>
<ul class='menu'>
%(taglist)s
</ul>
</div>
<div id='content'>
<div class='head'>
<h1><a href="%(indexpage)s">%(title)s</a></h1>
<p>%(description)s by %(editor)s</p>
</div>
%(htmlentries)s
</div>

</body>
</html>
"""

defaultBlogEntrySkeleton = u"""\
<h2><a href="%(link)s">%(title)s</a></h2>
<h3>Posted by %(author)s on %(publishedtime)s</h3>
<p><b>Tags:</b>  %(linkedTags)s</p>
<div>
%(content)s
</div>
<a name="comments"></a>
<p><b><a href='%(link)s#comments'>%(ncomments)s comments</a></b></p>
"""

defaultBlogCommentSkeleton = u"""\
<h3>%(title)s</h3>
<h4>Comment by <a href="%(authoruri)s">%(author)s</a> on %(published)s</h4>
<div>
%(content)s
</div>
"""


defaultRssSkeleton = u"""\
<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom='http://www.w3.org/2005/Atom' xmlns:openSearch='http://a9.com/-/spec/opensearchrss/1.0/' version='2.0'>
<channel>
<atom:id>%(blogid)s</atom:id>
<lastBuildDate>%(lastbuilddate)s</lastBuildDate>
<title>%(title)s</title>
<description>%(description)s</description>
<link>%(homeurl)s</link>
<managingEditor>%(editor)s</managingEditor>
<generator>%(generator)s</generator>
<openSearch:totalResults>16</openSearch:totalResults>
<openSearch:startIndex>1</openSearch:startIndex>
<openSearch:itemsPerPage>25</openSearch:itemsPerPage>
%(rssitems)s
</channel>
</rss>
"""

defaultRssEntrySkeleton = u"""\
<item>
<guid isPermaLink='false'>$(entryid)s</guid>
<pubDate>%(publishediso)s</pubDate>
<atom:updated>%(updatediso)s</atom:updated>
%(rsscategories)s
<title>%(title)s</title>
<description>%(encodedContent)s</description>
<link>%(fulluri)s</link>
<author>%(author)s</author>
</item>
"""


def stripUtfMarker(content) :
	import codecs
	return content.replace( unicode(codecs.BOM_UTF8,"utf8"), "")

def readUtf8(filename) :
	print "Reading",filename
	return stripUtfMarker(codecs.open(filename,'r','utf8').read())

def loadOrDefault(filename, defaultContent) :
	try: return readUtf8(filename)
	except: return defaultContent

def writeUtf8(filename, content) :
	import codecs, os
	print "Generating",filename
	path = filename.split("/")[:-1]
	for i in range(len(path)) :
		try : os.mkdir("/".join(path[:i+1]))
		except: pass
	basepath='../'*len(path)
	content=content.replace('<!--base-->','<base href="%s" />'%basepath)
	codecs.open(filename, "w",'utf8').write(content)

class WikiCompiler :

	def compileInlines(self, inlines) :
		self.inlines = [ (re.compile(wikipattern), substitution) 
			for wikipattern, substitution in inlines  ]
	def substituteInlines(self, line) :
		for compiledPattern, substitution in self.inlines :
			line = compiledPattern.sub(substitution, line)
		return line

	def openDiv(self, markers, divMatch):
		divType = divMatch.group(1)
		try : divDef = list(markers[divType])
		except : return False
		if len(divDef) == 3 :
			divDef[2] = divDef[2](divMatch)
		self.openBlock(*divDef)
		return True
	def openBlock(self,opening,closing, processor=None):
		self.closeAnyOpen()
		self.result.append(opening)
		self.closing=closing	
		if processor :
			self.processor=processor
	def closeAnyOpen(self) :
		if self.closing == "" : return
		if self.processor : self.result.append(self.processor(None))
		self.processor=None
		self.result.append(self.closing)
		self.closing=""

	def addToc(self, level, title) :
		self.toc.append( (level, title) )
		return len(self.toc)
	def buildToc(self) :
		"""Default, empty toc"""
		return ""

	def process(self, content) :
		self.itemLevel = ""
		self.closing=""
		self.result=[]
		self.spanStack = []
		self.toc = []
		self.vars = {
			'title': '',
			'author': '',
		}
		for line in content.splitlines() :
			self.processLine(line)
		self.processLine("")
		self.vars["content"] = ("\n".join(self.result)) % {
			'toc': self.buildToc(),
		}
		return self.vars


class LaTeXCompiler(WikiCompiler) :
	def __init__(self) :
		self.compileInlines(inlineLatexSubstitutions)
		self.headerPatterns = headersLatex
		self.processor = None
	def processLine(self, line) :
		newItemLevel = ""
		liMatch = li.match(line)
		quoteMatch = quote.match(line)
		headerMatch = header.match(line)
		varMatch = var.match(line)
		figMatch = fig.match(line)
		todoMatch = todo.match(line)
		annoMatch = anno.match(line)
		codeMatch = code.match(line)
		labelMatch = label.match(line)
		divMatch = div.match(line)
		preMatch = pre.match(line)
		if liMatch :
			self.closeAnyOpen()
			newItemLevel = liMatch.group(1)
			line = "%s\item %s" %("\t"*len(newItemLevel), liMatch.group(2) )
		while len(newItemLevel) < len(self.itemLevel) or  \
				self.itemLevel != newItemLevel[0:len(self.itemLevel)]:
#			print "pop '"+self.itemLevel+"','"+newItemLevel+"'"
			tag = "itemize" if self.itemLevel[-1] == "*" else "enumerate"
			self.result.append("%s\\end{%s}"%("\t"*(len(self.itemLevel)-1),tag))
			self.itemLevel=self.itemLevel[0:-1]
		if self.closing == r"\end{verbatim}" and line == "}}}" :
			self.closeAnyOpen()
			return
		elif line=="" :
			self.closeAnyOpen()
		elif self.processor : 
			self.processor(line)
			return
		elif varMatch :
			self.vars[varMatch.group(1)] = varMatch.group(2)
			return
		elif quoteMatch:
			if self.closing != "\\end{quotation}" :
				self.openBlock("\\begin{quotation}", "\\end{quotation}")
			line=line[1:] # remove the quotation indicator space
		elif figMatch :
			self.closeAnyOpen()
			flags = [ flag.strip() for flag in figMatch.group(3).split() if flag.strip() ]
			imageFlags = []
			if "rotated90" in flags :
				imageFlags.append("angle=90")
			if "halfSize" in flags:
				imageFlags.append("scale=.5")
			else:
				imageFlags.append("width=4.8in")
			sizeSpecifier = "[" + ",".join(imageFlags) + "]"
			print "flags:", sizeSpecifier
			self.openBlock(
				"\\begin{figure*}[htbp]\n"
				"\\begin{center}\\includegraphics%(size)s{%(img)s}\end{center}\n"
				"\\caption{%%%%"%{
					'img': figMatch.group(2),
					'size': sizeSpecifier,
					},
				"}\n\\label{%(id)s}\n"
				"\\end{figure*}\n"%{
					'id':figMatch.group(1)},
				)

			return
		elif codeMatch :
			self.closeAnyOpen()
			self.openBlock(
				r"\begin{lstlisting}",
				r"\end{lstlisting}",
				LaTeXCodeProcessor(codeMatch))
			return
		elif preMatch :
			self.closeAnyOpen()
			self.openBlock(
				r"\begin{verbatim}",
				r"\end{verbatim}",
				HtmlVerbatimProcessor())
			return
		elif todoMatch :
 			if enableLaTeXMarginNotes :
				line="\\marginpar{\\footnotesize TODO: %s}"%todoMatch.group(1)
			else: 
				line="\\footnote{\\footnotesize TODO: %s}"%todoMatch.group(1)
		elif annoMatch :
			annotator = annoMatch.group(1)
			text = annoMatch.group(2)
 			if enableLaTeXMarginNotes :
				line="\\marginpar{\\footnotesize %s: %s}"%(annotator,text)
			else: 
				line="\\footnote{\\footnotesize %s: %s}"%(annotator,text)
		elif labelMatch :
			line="\label{%s}"%labelMatch.group(1)
		elif headerMatch :
			self.closeAnyOpen()
			title = headerMatch.group(3)
			level = len(headerMatch.group(1))
			n=self.addToc(level,title)
			line = self.headerPatterns[level-1]%{
				"title": title,
				"label": n,
				"level": level,
			}
		elif not liMatch : 
			if divMatch :
				if self.openDiv(divMarkersLatex, divMatch) :
					return
				print "Not supported block class '%s'" % divMatch.group(1)
		# Equilibrate the item level
		while len(self.itemLevel) != len(newItemLevel) :
			self.closeAnyOpen()
#			print "push '"+self.itemLevel+"','"+newItemLevel+"'"
			levelToAdd = newItemLevel[len(self.itemLevel)]
			tag = "itemize" if levelToAdd == "*" else "enumerate"
			self.result.append("%s\\begin{%s}"%("\t"*len(self.itemLevel),tag))
			self.itemLevel += levelToAdd
		if self.processor :
			self.processor(line)
		else :
			line = self.substituteInlines(line)	
			self.result.append(line)


class HtmlCompiler(WikiCompiler) :
	def __init__(self, bibEntries={}) :
		self.compileInlines(inlineHtmlSubstitutions)
		self.headerPatterns = headersHtml
		self.bibEntries = bibEntries
		self.processor = None
	def buildToc(self) :
		result = []
		lastLevel = 0
		i=1
		result+=["<h2>Index</h2>"]
		result+=["<div class='toc'>"]
		for (level, item) in self.toc :
			while lastLevel < level :
				result += ["<ul>"]
				lastLevel+=1
			while lastLevel > level :
				result += ["</ul>"]
				lastLevel-=1
			result+=["<li><a href='#toc_%i'>%s</a></li>"%(i,item)]
			i+=1
		while lastLevel > 0 :
			result += ["</ul>"]
			lastLevel-=1
		result += ["</div>"]
		return "\n".join(result)

	def processLine(self, line) :
		newItemLevel = ""
		liMatch = li.match(line)
		quoteMatch = quote.match(line)
		headerMatch = header.match(line)
		varMatch = var.match(line)
		figMatch = fig.match(line)
		todoMatch = todo.match(line)
		annoMatch = anno.match(line)
		labelMatch = label.match(line)
		codeMatch = code.match(line)
		divMatch = div.match(line)
		preMatch = pre.match(line)
		if self.closing == "</pre>" and line == "}}}" :
			self.closeAnyOpen()
			return
		elif line=="" :
			self.closeAnyOpen()
			return
		elif self.processor : 
			self.processor(line)
			return
		elif varMatch :
			self.vars[varMatch.group(1)] = varMatch.group(2)
			print "Var '%s': %s"%(varMatch.group(1),varMatch.group(2))
			return
		if liMatch :
			self.closeAnyOpen()
			newItemLevel = liMatch.group(1)
			line = "%s<li>%s</li>" %("\t"*len(newItemLevel), liMatch.group(2) )
		while len(newItemLevel) < len(self.itemLevel) or  \
				self.itemLevel != newItemLevel[0:len(self.itemLevel)]:
#			print "pop '"+self.itemLevel+"','"+newItemLevel+"' "+self.itemLevel[-1]
			tag = "ul" if self.itemLevel[-1] == "*" else "ol"
			self.result.append("%s</%s>"%("\t"*(len(self.itemLevel)-1),tag))
			self.itemLevel=self.itemLevel[0:-1]
		if quoteMatch:
			if self.closing != "</blockquote>" :
				self.openBlock("<blockquote>","</blockquote>")
			line=line[1:] # remove the quoting indicator space
		elif figMatch :
			self.closeAnyOpen()
			self.openBlock(
				"<div class='figure' id='%(id)s'><img src='%(img)s' alt='%(id)s'/><br />"%{
						'id':figMatch.group(1),
						'img': figMatch.group(2),
						},
				"</div>")
			return
		elif codeMatch :
			self.closeAnyOpen()
			self.openBlock(
				"<code>",
				"</code>",
				HtmlCodeProcessor(codeMatch))
			return
		elif preMatch :
			self.closeAnyOpen()
			self.openBlock(
				"<pre>",
				"</pre>",
				HtmlVerbatimProcessor())
			return
		elif todoMatch :
			line=" <span class='todo'>TODO: %s</span> "%todoMatch.group(1)
		elif annoMatch :
			annotator = annoMatch.group(1)
			text = annoMatch.group(2)
			line=(" <a class='anno'><img alt='[Ann:%s]' src='stock_notes.png' />"+ 
				"<span class='tooltip'><b>%s:</b> %s</span></a> ")%(annotator,annotator,text)
		elif labelMatch :
			line=" <a name='#%s'></a>"%labelMatch.group(1)
		elif headerMatch :
			self.closeAnyOpen()
			title = headerMatch.group(3)
			level = len(headerMatch.group(1))
			n=self.addToc(level,title)
			line = self.headerPatterns[level-1]%{
				"title": title,
				"n": n,
				"level": level,
			}
		elif not liMatch : 
			if divMatch :
				if self.openDiv(divMarkersHtml, divMatch) :
					return
				print "Not supported block class '%s'" % divMatch.group(1)
			elif self.closing == "" :
				self.openBlock("<p>","</p>")
		# Equilibrate the item level
		while len(self.itemLevel) != len(newItemLevel) :
			self.closeAnyOpen()
#			print "push '"+self.itemLevel+"','"+newItemLevel+"'"
			levelToAdd = newItemLevel[len(self.itemLevel)]
			tag = "ul" if levelToAdd == u"*" else "ol"
			self.result.append("%s<%s>"%("\t"*len(self.itemLevel),tag))
			self.itemLevel += levelToAdd
		if self.processor :
			self.processor(line)
		else :
			line = self.substituteInlines(line)	
			self.result.append(line)

def needsRebuild(target, source) :
	if forceRebuild: return True
	if not os.path.exists(target) : return True
	if os.path.getmtime(target)<os.path.getmtime(source): return True
	if not os.access(skeletonFileName, os.F_OK) : return False
	if os.path.getmtime(target)<os.path.getmtime(skeletonFileName) : return True
	return False

def generateHtmlBibliography(outputFilename, bibfiles) :
	if not bibfiles : return
	print "Generating HTML bibliography..."
	try: import _bibtex as bibtex
	except: return generateHtmlBibliographyRaw(outputFilename, bibfiles)
	return generateHtmlBibliographyPretty(outputFilename, bibfiles)

def generateHtmlBibliographyRaw(outputFilename, bibfiles) :
	result = []
	bibfilename = "bibliography.bib.html"
	entry = re.compile(r"@\w*{([^,]*),")
	for bibfile in bibfiles :
		for line in codecs.open(bibfile,'r','utf8') :
			m = entry.search(line)
			if m and not 'comment' in line:
				id = m.group(1).strip()
				result += ["<a id='%s' />\n"%id]
			result.append(line)
	# TODO: Is it needed to have a 
	writeUtf8(bibfilename, skeleton%dict(
		content="<pre>"+"".join(result)+"</pre>",
		title="Bibliography",
		author="",
		revision="",
		prev="",
		next="",
		wikiSource='',
		))
	return {} # no hoverable bibliography

def generateHtmlBibliographyPretty(outputFilename, bibfiles) :
	import _bibtex as bibtex
	def bibIterator( file ) :
		while True :
			entry = bibtex.next(file)
			if entry: yield entry
			else: return
	entries = {}
	output = []
	for filename in bibfiles :
		bibfile = bibtex.open_file(filename,1)
		for id, kind, byteOffset, lineOffset, keys in bibIterator(bibfile) :
			output += [u"<p><a name='%s'></a><b>%s</b> <b>%s</b></p><ul>"%(id,kind,id)]
			entryDict = {}
			for key, value in keys.iteritems() :
				expanded = bibtex.expand(bibfile, value, -1)
				if len(expanded) is 3 :
					expanded = tuple(list(expanded)+[None])
				elif len(expanded) is 6 : # year
					expanded = expanded[0:-2]
				elif len(expanded) is not 4 : print "Warning: unknown bibliography tuple:", id, key, expanded; continue
				foo, bar, text, content = expanded
				if not text : continue
				text = unicode(text,'utf8')
				output += [u"<li><b>%s:</b> %s</li>" % (key, text)]
				entryDict[key]=text
			entryDict["kind"] = kind
			entries[id] = entryDict
			output += [ "</ul>" ]
	writeUtf8(outputFilename, skeleton%dict(
        content="\n".join(output),
        title="Bibliography",
        author="",
        revision="",
        prev="",
        next="",
        wikiSource='',
        ))
	return entries


skeletonFileName = "skeleton.html"
skeleton = loadOrDefault(skeletonFileName, defaultSkeleton)

# Generate bibliography
bibEntries = generateHtmlBibliography("bibliography.bib.html", glob.glob("*.bib"))

# Generate HTML with HTML content files + skeleton
for contentFile in glob.glob("content/*.html") :
	target = os.path.basename(contentFile)
	if not needsRebuild(target, contentFile) :
		print target, "is up to date."
		continue
	print "Generating", target, "from", contentFile, "..."
	content = readUtf8(contentFile)
	writeUtf8(target, skeleton%{'title':'', 'author':'','content':content})

# Generate LaTeX and HTML from wiki files

def fileNamesBasesForExtension(extension) :
	return set([ os.path.splitext(file)[0] for file in glob.glob("*."+extension) ])

# TeX skeletons are not generated from wiki files
texSkeletons = fileNamesBasesForExtension("tex") - fileNamesBasesForExtension("wiki")
# ...and contain \documentclass directive
texSkeletons = [ texSkeleton 
		for texSkeleton in texSkeletons
		if readUtf8(texSkeleton+".tex").find(r"\documentclass") != -1
	]

for contentFile in glob.glob("*.wiki") :
	base = os.path.basename(contentFile)
	target = "".join(os.path.splitext(base)[0:-1])+".html"
	targetTex = "".join(os.path.splitext(base)[0:-1])+".tex"
	if not needsRebuild(target, contentFile) :
		print target, "is up to date."
		continue
	content = readUtf8(contentFile)
	if enableHtml :
		print "Generating", target, "from", contentFile, "..."
		htmlResult = HtmlCompiler(bibEntries).process(content)
		htmlResult['wikiSource']=contentFile;
		writeUtf8(target, skeleton%htmlResult)
	if enableLaTeX and len(texSkeletons):
		print "Generating", targetTex, "from", contentFile, "..."
		texResult = LaTeXCompiler().process(content)
		writeUtf8(targetTex, texResult['content'])


print "Generating blog..."

def readBlogEntries(blog) :
	blogEntries = []
	tags=set()
	blog.comments=[
		HtmlCompiler(bibEntries).process(readUtf8(commentFile))
			for commentFile in glob.glob(u"blog/*.comment")
	]
	for contentFile in glob.glob(u"blog/*.wiki") :
		entry = HtmlCompiler(bibEntries).process(readUtf8(contentFile))
		entry['name'] = os.path.splitext(os.path.basename(contentFile))[0]
		entry.setdefault('tags',"")
		entry['splittedTags']=[tag.strip() for tag in entry["tags"].split(",") if tag!=""]
		tags=tags.union(entry['splittedTags'])
		entry['linkedTags']=', '.join([
			"<a href='blog/tag/%(tag)s.html'>%(tag)s</a>"%{'tag':tag} 
				for tag in entry['splittedTags']])
		entry["rsscategories"]="\n".join([
			"<category domain='http://www.blogger.com/atom/ns#'>%s</category>"%tag 
				for tag in entry["splittedTags"] ])
		try:
			publishedTime = datetime.strptime(entry['published'], "%Y-%m-%d %H:%M:%S")
		except KeyError :
			try :
				publishedTime = datetime.strptime( os.path.basename(contentFile)[:16], "%Y-%m-%d-%H-%M")
			except ValueError :
				print >> sys.stderr, "Warning: Cannot deduce publication date for '%s', using current time."%contentFile
				publishedTime = datetime.utcnow()
		try :
			updatedTime = datetime.strptime(entry['updated'], "%Y-%m-%d %H:%M:%S")
		except KeyError :
			updatedTime = datetime.utcfromtimestamp(os.path.getmtime(contentFile))

		entry["publishedtime"] = str(publishedTime)
		entry["updatedtime"] = str(updatedTime)
		entry["publishediso"] = publishedTime.isoformat()
		entry["updatediso"] = updatedTime.isoformat()
		entry["entryid"] = "tag:blogger.com,1999:blog-%s.post-%s"%(blog.blogid,entry['id'])
		entry['link'] = u"blog/%02i/%02i/%s.html"%(publishedTime.year-2000,publishedTime.month,entry["name"])
		from xml.sax.saxutils import escape
		entry["encodedContent"] = escape(entry["content"])
		# fulluri was: http://vokicodder.blogspot.com/2007/07/simplifying-spectral-processing-in-clam.html
		entry["fulluri"] = blog.baseurl + "/" + entry["link"]
		entry["comments"]=[
			comment for comment in blog.comments
			if comment['inreplyto'] == entry['id'] 
			]
		entry["comments"].sort(key=lambda a: a['published'])
		entry["ncomments"] = len(entry["comments"])
		blogEntries.append(entry)
	blogEntries.sort(key=lambda a: a['publishediso'], reverse=True)
	return blogEntries, tags

def generateBlog(blog, blogEntries, tags) :
	if not blogEntries: return
	tagPages = dict([(tag,[]) for tag in tags])
	blog.indexpage = 'blog/index.html'
	blogCommentScheleton = loadOrDefault("blog/commentScheleton.html", defaultBlogCommentSkeleton)
	blogEntryScheleton = loadOrDefault("blog/entryScheleton.html", defaultBlogEntrySkeleton)
	blogScheleton = loadOrDefault("blog/skeleton.html", defaultBlogSkeleton)
	blogRssEntryScheleton = loadOrDefault("blog/rssEntryScheleton.rss", defaultRssEntrySkeleton)
	blogRssScheleton = loadOrDefault("blog/rssScheleton.rss", defaultRssSkeleton)
	htmlentries = []
	rssItems = []
	for entry in blogEntries :
		print entry['publishediso'], entry['name'] , "|" , entry['title'] , "[" + entry["tags"]+']'
	for entry in blogEntries :
		targetBlog = entry['link']
		composed = blogEntryScheleton%entry
		htmlentries.append(composed)
		for tag in entry['splittedTags'] :
			tagPages[tag].append(composed)
		rssItems.append(blogRssEntryScheleton%entry)

	taglist=[(tag,len(entries)) for tag, entries in tagPages.iteritems()]
#	taglist.sort(key=lambda a : a[1],reverse=True)
	minTagItems = min(nitems for tag,nitems in taglist)-1
	maxTagItems = max(nitems for tag,nitems in taglist)
	blog.taglist = "\n".join([
		"<li class='cloud%s'><a href='blog/tag/%s.html'>%s(%i)</a></li>"%(
			(nitems-minTagItems)*10/maxTagItems,tag,tag,nitems) for tag,nitems in taglist])
	for entry in blogEntries :
		blog.htmlentries = "".join(
			[(blogEntryScheleton % entry)] +
			[blogCommentScheleton % comment for comment in entry['comments']]
			)
		writeUtf8(entry['link'],blogScheleton % blog.__dict__)
		

	blog.htmlentries = "\n".join(htmlentries)
	blog.rssitems = "\n".join(rssItems)
	writeUtf8(blog.indexpage, blogScheleton%blog.__dict__)
	writeUtf8("blog/feed.rss", blogRssScheleton%blog.__dict__)
	tagNotice = """<div class='blog_tagnotice'>Showing only entries labeled as <b>%s</b>.
<a href='%s'>Show all entries</a></div>"""
	for tag, tagEntries in tagPages.iteritems() :
		blog.htmlentries = "\n".join([tagNotice%(tag,blog.indexpage)]+tagEntries)
		writeUtf8("blog/tag/%s.html"%tag,blogScheleton%blog.__dict__)

from datetime import datetime
# TODO: Should be a config file with default values
class blogConfig :
	title = "Your title here"
	blogid = "tag:blogger.com,1999:blog-36421488"
	editor = "You"
	description = "Your blog description here"
	generator = "WiKo"
	lastbuilddate = datetime.utcnow().ctime()
	baseurl = "http://yourblog.blogspot.com/" # The base url for the blog pages to access them remotely (rss)
	homeurl = "http://yourblog.blogspot.com/home.html" # The home page for the blog

	for configfile in ["blog/blog.config"] :
		if not os.access(configfile,os.R_OK) : continue
		execfile(configfile)


blogEntries, tags = readBlogEntries(blogConfig)
generateBlog(blogConfig, blogEntries, tags)


print "Generating download zones..."

def humanReadableSize(filename) :
	if os.path.isdir(filename) : return ""
	sufixes = [
		("P",1<<50),
		("T",1<<40),
		("G",1<<30),
		("M",1<<20),
		("K",1<<10),
	]
	size = os.path.getsize(filename)
	for suffix, scale in sufixes:
		if size/scale > 1.1:
			return "%.2f %sb"%(float(size)/scale, suffix)
	return str(size)+" b"

def humanReadableTime(filename) :
	if os.path.isdir(filename) : return ""
	return str(datetime.fromtimestamp(os.path.getmtime(filename)))

def generateDownloadZones(dirs, skeletonFilename, blacklist) :
	lineTemplate = "<tr><td style='width:100%%'><a href='%(filename)s'>%(filename)s</a></td><td>%(size)s</td><td>%(date)s</td></tr>"
	skeleton = readUtf8(skeletonFilename)
	for title, dirname in dirs:
		dirname = os.path.expanduser(dirname)
		if not os.access(dirname, os.X_OK):
			print "Not available: %s"%dirname
			continue
		print "Generating download index at '%s'"%dirname
		files = os.listdir(dirname)
		files = filter((lambda a : a not in blacklist ), files) # Filter blacklisted
		dirs = [dir+"/" for dir in filter((lambda a : os.path.isdir(os.path.join(dirname, a)) ), files) ]
		files = filter((lambda a : not os.path.isdir(os.path.join(dirname, a)) ), files) # Filter dirs
		files.sort()

		table = "\n".join( [ lineTemplate%{
				'filename': filename,
				'size': humanReadableSize(os.path.join(dirname, filename)),
				'date': humanReadableTime(os.path.join(dirname, filename)),
			} for filename in dirs + files ])
		content = "<h1> Downloads </h1>"
		content += "<h2> %s </h2>"%title
		content += "\n".join(["<table style='white-space:nowrap' width='100%'>",table,"</table>"])
		index = skeleton%{
			'title': title,
			'content': content,
			'author':'generated',
			'wikiSource':''
		}
		writeUtf8(os.path.join(dirname,"index.html"),index)

dzConfig = {
	'dirs' : [],
	'blacklist' : [
		"index.html",
		"style.css",
		"img",
	],
	'template' : skeletonFileName
}
try :
	dzConfig.update(eval(file("downloadZones.wiko").read()))
except :
	pass
if len(dzConfig['dirs']) :
	generateDownloadZones(dzConfig['dirs'], dzConfig['template'], dzConfig['blacklist'])

#os.system("(cd img; bash ./generate_figures.py)")

if enableLaTeX :
	for texSkeleton in texSkeletons :
		os.system("bibtex %s" % texSkeleton)
		os.system("pdflatex %s" % texSkeleton)


